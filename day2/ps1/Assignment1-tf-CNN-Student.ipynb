{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "25c7093b-556b-4c08-b249-b30edea100f7"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "631f9391-dba5-480c-a928-2950874f2998"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "MNIST = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "82e859b9-c8ba-4e31-add1-d13a9a38dce0"
    }
   },
   "source": [
    "<img src=\"cnn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d792b8a5-fb49-484c-8957-48f4e01d37b2"
    }
   },
   "source": [
    "### CNN Configurations\n",
    "Understand how the configuration of the CNN is set based on the image above. \n",
    "* Assume that each convolutional layer is zero padded appropriately so that the convolutional layer does not decrease the width or height of the image. \n",
    "* After each convolutional layer and ReLu layer, there will be a max pool layer which decreases the image size by 2.\n",
    "* Note that the number of filters in the convolution corresponds to the number of channels of the output volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0b2ff275-5908-4d83-b982-af49d1915787"
    }
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "img_size = 28                               # MNIST images are 28x28# Size of MNIST image in 1D array\n",
    "img_size_flat = img_size * img_size         # Size of MNIST image in 1D array\n",
    "num_channels = 1                            # 1 channel because images are grayscale\n",
    "num_classes = 10                            # Number of classes, one class for each of 10 digits.\n",
    "\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "af0ce285-da21-44f3-aef9-b82069159e5f"
    }
   },
   "source": [
    "Fill in the following helper functions to create new weight and bias tensors of a given shape. \n",
    "* Let the weights be initialized to values from the truncated normal distribution with a standard deviation of 0.1.\n",
    "* Let the bias be initialized to a tensor of 0.1s. Note that the input to new_biases() will be a scalar number so accordingly decide the shape of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbpresent": {
     "id": "5b8f020c-f121-4c74-a87d-b5a9b7302f5c"
    }
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def new_biases(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=[shape]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "93044d7b-ce2b-4adf-8ada-a104198c5979"
    }
   },
   "source": [
    "### Convolutional Layer\n",
    "Fill in the following function to create a new convolutional layer using tf.layers.conv2d() by first creating a convolutional layer, then using pooling if required, then applying ReLU.\n",
    "* Make sure zero padding is appropriately used so the width and height of the output of the convolutional layer match that of the input layer\n",
    "* Use a stride of 1 in all directions\n",
    "* If use_pooling = True, use 2x2 max pooling with tf.layers.max_pooling2d() to half the width and height of the input. Choose the appropriate stride for the pooling step\n",
    "    * Hint: Use the formula $W_2 = \\frac{W_1-F}{S} + 1$ where $W_2 = \\frac{W_1}{2}$ to calculate the appropriate stride\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "1a46bf01-a353-49d3-8684-e982b38b3636"
    }
   },
   "outputs": [],
   "source": [
    "# Fill in the dots\n",
    "def new_conv_layer(input_layer, filter_size, num_filters, use_pooling=True):  \n",
    "    \n",
    "    output = tf.layers.conv2d(inputs=..., kernel_size = ..., \n",
    "                              filters=..., padding = 'SAME', strides = ...)\n",
    "    \n",
    "    if use_pooling:\n",
    "        output = tf.layers.max_pooling2d(inputs = ..., pool_size = ..., strides = ...)\n",
    "        \n",
    "    output = tf.nn.relu(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above function, but use tf.nn.conv2d() this time to create the convolutional layer.\n",
    "* Remember: Unlike while using tf.layers.conv2d(), tf.nn.conv2d() requires the actual filter tensor as an input instead of just the size of the filter\n",
    "    * To do this, use the new_weights() function defined above.\n",
    "    * Also remember to add a bias for each filter after creating a convolutional layer with tf.nn.conv2d(). tf.layers.conv2d() adds a bias tensor by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in the dots\n",
    "\n",
    "def new_conv_layer_nn(input_layer, filter_size, num_filters, use_pooling=True):  \n",
    "    input_shape = input_layer.get_shape().as_list()\n",
    "    w_shape = [..., ..., input_shape[3], ...]\n",
    "    weights = new_weights(w_shape)\n",
    "    biases = new_biases(...)\n",
    "    \n",
    "    output = tf.nn.conv2d(input=..., filter = ..., padding = 'SAME', strides = ...)\n",
    "    output += biases\n",
    "    \n",
    "    if use_pooling:\n",
    "        output = tf.layers.max_pooling2d(inputs = output, pool_size=2, strides = 2)\n",
    "        \n",
    "    output = tf.nn.relu(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dimensions to make sure that both new_conv_layer functions work as expected.\n",
    "<br>\n",
    "* Create a placeholder value for each image with shape [batch size, image flattened size]\n",
    "* Reshape that placeholder into the shape [batch size, image height, image width, number of channels]. This is the format of the input that is required for both tf.layers.conv2d() and tf.nn.conv2d()\n",
    "    * Hint: Using -1 as one of the lengths of a dimension causes tensorflow to infer the length of that dimension depending on the size of the input and the lengths of the other dimensions provided. This will be useful because you don't yet know what the batch size is.\n",
    "* Create a placeholder value for each label with shape [batch size, number of classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbpresent": {
     "id": "e55bf768-3a35-4cf3-8122-b72ab918f98d"
    }
   },
   "outputs": [],
   "source": [
    "#Fill in the dots\n",
    "\n",
    "X = tf.placeholder(...)\n",
    "x_img = tf.reshape(X, [-1, img_size, img_size, num_channels])\n",
    "y = tf.placeholder(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using the new_conv_layer() function created above, create layer 1 and layer 2 of the CNN based on the configuration of the CNN and the image above. \n",
    "* Check the shape of the output of layer 1 and layer 2 to make sure they are accurate. \n",
    "* Change new_conv_layer() function to new_conv_layer_nn() and make sure the output shapes are still accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbpresent": {
     "id": "21d4d45d-b8fd-43d1-8ff9-36a5ab263010"
    }
   },
   "outputs": [],
   "source": [
    "#Fill in the dots\n",
    "\n",
    "layer_conv1 = new_conv_layer(input_layer=..., filter_size=..., num_filters=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbpresent": {
     "id": "d2243645-bfb5-417d-8134-b2e07ad47c63"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "2eb8c35f-664b-40c3-9626-08937ee9501c"
    }
   },
   "outputs": [],
   "source": [
    "#Fill in the dots\n",
    "\n",
    "layer_conv2 = new_conv_layer(input_layer=..., filter_size=..., num_filters=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "6ef75c1a-bef0-4c3e-bea0-1042d63b00b2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers\n",
    "Understand how this function to flatten a given layer of shape [batch size, ...] into [batch size, number of features] works\n",
    "* Hint: Tensor_Shape.num_elements() returns the total number of elements in a tensor of given shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "93b8cd1e-53fa-4ec8-8b85-f09752301a47"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    num_features = layer.get_shape()[1:4].num_elements()\n",
    "    return tf.reshape(layer, [-1, num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for a fully connected layer with the input layer having shape [batch size, number of input features] and the output layer having shape [batch size, num_outputs]\n",
    "* Define the weight and bias tensors and apply them on the input layer\n",
    "* Use a ReLU activation if appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c8c4b28c-99f8-4b5f-a429-f5ed72923c74"
    }
   },
   "outputs": [],
   "source": [
    "#Fill in the dots\n",
    "\n",
    "def new_fc_layer(layer, num_outputs, use_relu=True):\n",
    "    num_inputs = layer.get_shape().as_list()[1]\n",
    "    w = new_weights(shape = [num_inputs, ...])\n",
    "    b = new_biases(shape = ..)\n",
    "    \n",
    "    layer = ...\n",
    "    \n",
    "    if use_relu:\n",
    "        layer = ...\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the last convolutional layer and check that its shape is equal to the product of the last three dimensions of layer_conv2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "f2dbf140-5d5c-44ed-abad-db5050350882"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fill in the dots\n",
    "\n",
    "layer_flat = flatten_layer(...)\n",
    "layer_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a fully connected layer of the appropriate size based on the CNN configurations and check the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "86417dfd-e697-41f2-a178-32a046a339b1"
    }
   },
   "outputs": [],
   "source": [
    "#Fill in the dots\n",
    "\n",
    "layer_fc1 = new_fc_layer(layer = ..., num_outputs = ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "9e0fc369-0225-4a0f-9b8e-5d6aeb998343"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout/mul:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fill in the dots (Optional)\n",
    "\n",
    "#keep_prob = tf.placeholder(...)\n",
    "#layer_fc1 = tf.nn.dropout(...)\n",
    "#layer_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the final fully connected layer and check the size. ReLu is set to fall because we need access to the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ae1441dc-8e90-422d-bd55-97c0f6b6c9ed"
    }
   },
   "outputs": [],
   "source": [
    "#Fill in the dots\n",
    "\n",
    "layer_fc2 = new_fc_layer(layer = ..., num_outputs = ..., use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbpresent": {
     "id": "abce0e8d-b796-478f-8c22-d6df83ecdd5e"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply softmax to the final fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "92c7af29-58c5-4c9f-a6be-c16360fd4ffc"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following variables of the class of the predicted and true y value by using argmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-9c347b2d38b6>:1: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From <ipython-input-21-9c347b2d38b6>:2: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension = 1)\n",
    "y_cls = tf.argmax(y, dimension = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization and Accuracy\n",
    "Set entropy to be cross entropy and the loss to be the mean of the entropy. Use the Adam Optimizer with a learning rate of 0.01 to minimize the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b99a3071-61ab-423a-a328-18d813bcb5fc"
    }
   },
   "outputs": [],
   "source": [
    "#Fill in the dots\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits = ..., labels = ...)\n",
    "loss = tf.reduce_mean(...)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=...).minimize(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy by:\n",
    "* Checking if y_pred_cls = y_cls and casting this value as a float\n",
    "* Finding the mean of y_pred_cls = y_cls for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5efaf5a4-f48b-4b06-b920-6a9bde812134"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_cls, y_cls), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running \n",
    "Create a new interactive session and initialize all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "36d65090-1a76-4f18-b72c-794b04434df7"
    }
   },
   "outputs": [],
   "source": [
    "#Fill in the dots\n",
    "\n",
    "sess = ...\n",
    "sess.run(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the optimize function which will run a certain number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(epochs):\n",
    "    global total_epochs\n",
    "    batch_size = 64\n",
    "    num_batches = int(MNIST.train.num_examples/batch_size)\n",
    "    for epoch in range(total_epochs, total_epochs+epochs):\n",
    "        total_loss = 0\n",
    "        for batch in range(num_batches):\n",
    "            x, y_ = MNIST.train.next_batch(batch_size)\n",
    "            _, l = sess.run([optimizer, loss], feed_dict = {...})\n",
    "            total_loss += l\n",
    "        print(\"Epoch {0}: {1}\".format(epoch, total_loss))\n",
    "    total_epochs += epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize for a few iterations and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbpresent": {
     "id": "7a90cd73-e8cd-4eba-8cff-a8a7f9f5f2d4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 180.70307449204847\n",
      "Epoch 1: 108.97698271943955\n",
      "Epoch 2: 101.18824915075675\n",
      "CPU times: user 6min 47s, sys: 43.7 s, total: 7min 31s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "optimize(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbpresent": {
     "id": "317cda7e-01c9-4d33-89f2-ed7e4e82db12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing accuracy ...\n",
      "Accuracy 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "print(\"Computing accuracy ...\")\n",
    "X_batch, y_batch = MNIST.test.next_batch(MNIST.test.num_examples)\n",
    "total_accuracy = sess.run(accuracy, feed_dict={...})\n",
    "\n",
    "print (\"Accuracy {0}\".format(total_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extra Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout\n",
    "Add a dropout layer after the first fully connected layer by creating a placeholder keep_prob, which is a parameter to tf.nn.dropout(). This allows dropout to be on during training and off during testing. When training the model, set keep_prob to a fraction (such as 0.5) and when testing, set keep_prob to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
